{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More formal: Stability and accuracy.**\n",
    "\n",
    "Recall that we defined the difference between the exact and approximate solution is the error. Like $y(t)$ it is a function that is in principle continuous,\n",
    "\\begin{equation}\n",
    "\\epsilon(t) \\equiv y(t) - \\overline{y}(t).\n",
    "\\end{equation}\n",
    "\n",
    "Linearizing as before, the error obeys the *linear differential equation*\n",
    "\n",
    "$$\n",
    "\\frac{d\\epsilon}{dt} = J_n \\epsilon.\n",
    "$$\n",
    "or, letting $z = J_n t$,\n",
    "$$\n",
    "\\frac{d\\epsilon(z)}{dz} = \\epsilon(z).\n",
    "$$\n",
    "\n",
    "An integrator for $y$ also maps the error from $\\epsilon_n \\rightarrow \\epsilon_{n+1}$,\n",
    "\\begin{equation}\n",
    "\\epsilon_{n+1} = R(z) \\epsilon_{n}.\n",
    "\\end{equation}\n",
    "\n",
    "An integrator may be unstable, conditionally stable, A-stable or L-stable.\n",
    "\n",
    "Of these, A-stability and L-stability are important and distinct types of stability.\n",
    "\n",
    "**A stability**:\n",
    "\n",
    "An integrator is A-stable if\n",
    "\\begin{equation}\n",
    "\\boxed{|R(z)|<1 \\: \\forall Re(z) < 0.}\n",
    "\\end{equation}\n",
    "\n",
    "This just means that if the differential equation is supposed to decay to zero $(z < 0)$, its numerical approximation does not grow without bound.\n",
    "\n",
    "**L stability**\n",
    "\n",
    "If an integrator is A-stable, it may also be L-stable if \n",
    "\\begin{equation}\n",
    "\\boxed{\\lim_{z\\rightarrow \\infty}R(z) = 0}\n",
    "\\end{equation}\n",
    "\n",
    "L stability means that the integrator is stable for arbitrarily large time steps. This is a very important feature when we discuss solutions to stiff differential equations.\n",
    "\n",
    "**Exercise:** Show that the forward Euler method is neither A- nor L-stable. but that the backward Euler method is L-stable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy**\n",
    "\n",
    "Just because a method is stable doesn't mean that it is *accurate*. It may well converge to the wrong answer or to a poor apprxoimation to the problem at hand.\n",
    "\n",
    "Indeed, just because a method is unstable *does not mean* that it cannot be accurate.\n",
    "\n",
    "Often, we can't know what the true form of $\\epsilon(t)$ is, but we can bound it based on Lagrange's estimate, also known as the Taylor Remainder theorem. Consider the Taylor series of order $k$ a function that is analytic about a point $t_n$, \n",
    "\\begin{equation}\n",
    "y(t) = \\sum_{l=0}^k c_l (t - t_n)^l + \\epsilon(t).\n",
    "\\end{equation}\n",
    "Simply differentiate to find the expansion coefficients, $c_l$\n",
    "\\begin{equation}\n",
    "c_l = \\frac{1}{l!}y^{(l)}(t_n),\n",
    "\\end{equation}\n",
    "where $y^{(l)}$ is the $l^{th}$ time derivative of $y$ with respect to $t$.\n",
    "\n",
    "The Remainder theorem says that the error $\\epsilon(t)$ about $t = t_n$ has, as its lowest order polynomial, a function that grows as $(t - t_n)^{k+1}$. We usually write that using the big-O notation, \n",
    "\\begin{equation}\n",
    "\\epsilon(t) = {\\cal O}((t - t_n)^{k+1}),\n",
    "\\end{equation}\n",
    "\n",
    "Giving the familar form \n",
    "\\begin{equation}\n",
    "y(t) = \\sum_{l=0}^k \\frac{1}{l!} y^{(l)}(t_n)(t - t_l)^l + {\\cal O}((t - t_n)^{k+1})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Higher order methods:**\n",
    "\n",
    "If we want more accurate methods, we have to do more work.\n",
    "\n",
    "Consider the Taylor expansion of $y$ about $t$ for $h>0$,\n",
    "\n",
    "\\begin{equation}\n",
    "y(t +h) = y(t) + y'(t)h + \\frac{y''(t)}{2}h^2 + {\\cal O}(h^3)\n",
    "\\end{equation}\n",
    "\n",
    "But there is also an expansion in the negative direction,\n",
    "\n",
    "\\begin{equation}\n",
    "y(t - h) = y(t) - y'(t)h + \\frac{y''(t)}{2}h^2 + {\\cal O}(h^3)\n",
    "\\end{equation}\n",
    "\n",
    "Subtracting the two equations gives\n",
    "\\begin{equation}\n",
    "y(t+h) - y(t-h) = 2 y'(t) h + {\\cal O}(h^3)\n",
    "\\end{equation}\n",
    "\n",
    "Since $y'(t) = f(y,t)$, we have a formula\n",
    "\\begin{equation}\n",
    "y(t+h) = y(t-h) + 2f( y(t),t )h + {\\cal O}(h^3)\n",
    "\\end{equation}\n",
    "\n",
    "Setting $h\\rightarrow h/2$ and shifting $t\\rightarrow t+h/2$,\n",
    "\\begin{equation}\n",
    "y(t+h) = y(t) + f( y(t+h/2),t+h/2)h + {\\cal O}(h^3)\n",
    "\\end{equation}\n",
    "\n",
    "To maintain accuracy to order $h^2$, we have to compute $y(t+h/2)$ to order $h$, $f(y(t+h/2),t+h/2) = f( y(t) + f(y(t),t)h/2,t+h/2 ) + {\\cal O}(h^2)$.\n",
    "\n",
    "Putting it all together, we've got an expression accurate to $h^2$-which is to say that the error is a polynomial of order ${\\cal O}(h^3)$. It goes in two steps,\n",
    "$$\n",
    "y_n^* =  \\overline{y}_n + f(\\overline{y}_n,t_n)h/2\n",
    "$$\n",
    "$$\n",
    "\\overline{y}_{n+1} = \\overline{y}_n + hf(y_n^*,t_n + h/2)\n",
    "$$\n",
    "\n",
    "This is a two-step second-order accurate method. While the accuracy is greater, the penalty (there's always a price) is that you need two evaluations of $f(y,t)$ to take one step.\n",
    "\n",
    "*Weighing computational expense*\n",
    "We've seen that the explicit Euler is conditionally stable and is only order 1 accurate. On the other hand, you're only evaluating the function $f(y,t)$ once to take a step. Often, the evaluation of the function is the most expensive part of the computation. So, is it better to take super small time steps so that the method is stable, or to take larger time steps and use a higher order integrator?\n",
    "\n",
    "These kinds of strategic decisions are commonplace in numerical work. In the case of differential equations, various types of solution schemes can provide important checks to make sure that not only is your solution converging, but that is converging to the right answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A critical part of the Chapman cycle involves the Lindemann-Hinschelwood mechanism,\n",
    "\n",
    "$$\n",
    "O\\cdot + O_2 + M \\rightarrow O_3 + M\n",
    "$$\n",
    "\n",
    "The law of mass action for ozone says\n",
    "\\begin{equation}\n",
    "\\frac{d[O_3]}{dt} = k[O\\cdot][O_2][M].\n",
    "\\end{equation}\n",
    "\n",
    "where $M$ is a buffer gas, usually nitrogen, that absorbs the excess energy of the reaction and stabilizes ozone. Near the bifurcation regime, the partial pressure of ozone obeys an effective rate equation,\n",
    "\n",
    "$$\n",
    "\\frac{d[O_3]}{dt} = -\\gamma[O_3] + \\alpha [O_3]^2\n",
    "$$.\n",
    "\n",
    "Measuring time in units of $\\gamma^{-1}$ and concentration in terms of the inital partial pressure of $[O_3]$, we have a differential equation\n",
    "$$\n",
    "\\frac{dy}{dt} = -y + \\beta y^2.\n",
    "$$\n",
    "\n",
    "where $\\beta = \\alpha[O_3(0)]/\\gamma$ and $y(t) = [O_3(t)]/[O_3(0)]$.\n",
    "\n",
    "Let's use this equation to test the accuracy of the second-order method compared to forward Euler. We'll try to find the bifurcation threshold using both of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `~/github/CHEM-5555-Examples-Solutions/Project.toml`\n",
      "  \u001b[90m[5fb14364] \u001b[39mOhMyREPL v0.5.28\n",
      "  \u001b[90m[91a5bcdd] \u001b[39mPlots v1.40.9\n",
      "  \u001b[90m[f2b01f46] \u001b[39mRoots v2.2.4\n",
      "  \u001b[90m[3a884ed6] \u001b[39mUnPack v1.0.2\n",
      "  \u001b[90m[8dfed614] \u001b[39mTest v1.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/github/CHEM-5555-Examples-Solutions`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.status()\n",
    "Pkg.activate(\".\")\n",
    "Pkg.instantiate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"JDE_ODE_Base.jl\")\n",
    "using .JDE_ODE_Base\n",
    "import .JDE_ODE_Base: step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the integrators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct ForwardEuler <: ODEIntegrator end\n",
    "function step(problem::ODEProblem, ::ForwardEuler, yₙ::Float64, tₙ::Float64)\n",
    "    @unpack f, h = problem\n",
    "    return yₙ + h*f(yₙ,tₙ)\n",
    "end\n",
    "\n",
    "struct Midpoint <: ODEIntegrator end\n",
    "function step(problem::ODEProblem, ::Midpoint, yₙ::Float64, tₙ::Float64)\n",
    "    @unpack f, h = problem\n",
    "    k₁ = f(yₙ, tₙ)\n",
    "    k₂ = f(yₙ + h/2*k₁, tₙ + h/2)\n",
    "    return yₙ + h*k₂\n",
    "end\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
